\section{Related work}
Mining repositories to extract knowledge from them has been an object of study for several years.

In \cite{Ying_2004} it is proposed an approach that, when developers are editing a file, recommends other files that may also need edits. This is done by analyzing which files have frequently changed together in the past (using a version control system), and applying a frequent pattern mining algorithm to them. For a better analysis, they consider not only files that were committed together, but also files that were committed by the same author in a short period of time, as they most likely refer to the same task. Finally, they also filter commits with too many files changed, as these commits usually don't refer to a single task and so aren't relevant for recommendations.

A frequent pattern mining algorithm is also used in \cite{Kagdi_2007}. The knowledge of files frequently changed together (called "change sets") is used to uncover "traceability between source code and other artifacts", like documentation. They also use heuristics like changes in a small period of time ("\textbf{time-interval}"), changes by the same author ("\textbf{committer}"), and a mix of both ("\textbf{time-interval + committer}") to group change sets that probably refer to the same task/change. By evaluating the approach on several versions of \textit{KDE} (K Desktop Environment), the authors find that this approach is able to find links between different types of artifacts like "source code files, change logs, user documentation, and build files" with high accuracy.

In \cite{Alali_2008}, an analysis of different metrics of commits like number of changed files, number of changed lines and hunks is done to categorize a commit from "extra small to extra large". The categorization of a single commit is always done relative to predefined criteria, obtained from all commits from the same repository. This predefined criteria is obtained (for each metric) by calculating the statistical 5-point summary (Minimum, Q1, Median, Q3, Maximum). Plotting these values into a Boxplot allows for a division into 5 regions, as seen in figure \ref{fig:boxplot-commit-size}. A single commit is then classified according to where the metrics fall in this Boxplot.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.2]{imgs/boxplot-commit-size.png}
    \caption{Boxplot of the regions for classification of commit size. From \cite{Alali_2008}}
    \label{fig:boxplot-commit-size}
\end{figure}

Applying this to the commits of nine open source repositories (of various sizes and languages), and using messages in commits' log files to determine the activity performed, let the authors conclude that there is some evidence the category of a commit can indicate the activity being performed.

The problem of assigning the best code reviewer(s) to a given pull request affects many players in the industry, with \cite{Yu_2016} mentioning that "the management of pull requests is identified as the most important project activity on GitHub". Different authors try to solve this problem with past software history change analysis. A tool called "Review Bot" was developed in \cite{Balachandran_2013} mainly to aid code reviewers in the process of reviewing pull requests, by using static analysis techniques to check for code style violations and bad patterns. The tool also generates code reviewers recommendations based on \textit{line change history}, and it does so with an accuracy of 60\% to 90\%. Another approach to recommend reviewers, but based on file paths, is described in \cite{Thongtanunam_2015}. The tool they propose is applied to a new review, and the recommendations are based on who reviewed similar file paths in the past as the ones changed in that review. Finding similar file paths is done by string comparison techniques, like \textbf{Longest Common Prefix} (files under the same directory are considered similar), \textbf{Longest Common Suffix} (files with the same name are considered similar), \textbf{Longest Common Substring} and \textbf{Longest Common Subsequence} (files under a similar directory structure are similar). This approach was evaluated on a total of 42,045 reviews across 5 different open source projects (Android Open Source Project (AOSP), OpenStack, Qt and LibreOffice), and it "correctly
recommended 79\% of reviews with a top 10 recommendation" - 3 times better than ReviewBot.
% Valerá a pena partir o parágrafo em cima? Parece um bloco de texto um bocado grande demais, mas é tudo relacionado...

% Este do Schuler foi posto aqui (estava mais em baixo) pois está relacionado com este assunto, acho que faz mais sentido.
Both of these papers address the issue by ultimately assuming that developers who changed a file most often have the most familiarity and expertise in that file. However,   \cite{Schuler_2008} assume that developers who use a \textit{functionality} most often, by calling a method, are the most familiar with it. They introduce the notion of \textit{usage based expertise}, which, together with \textit{implementation based expertise} (those who modified methods are most familiar with them), is used to create \textbf{expertise profiles}. To build this profile for a developer, they looked at and counted all the methods that the developer changed (or added) and used in past commits. Then, it's easy to find developers who have experience with using a given module - it's a matter of considering a set with all methods of that module, and counting intersections with profiles. One application mentioned in the paper is in the calculation of neighborhoods of developers - sets of developers with the most similar expertise. This could help with the creation of teams (with members from different projects) to discuss usage of an API, or with scheduling meetings with developers working on "related parts of the code", or even "to choose developers for training of their skills", by identifying who would need training in a given technology the most.

There are also other interesting conclusions and associations that can be extracted with the data of different repositories. Not much is known regarding what happens to the code quality of programmers very familiar with a language when they switch to another they don't use that often. This is explored in \cite{Horschig_2018}, where the authors compared Python code written by Java and C++ developers. They found, for example, that C++ programmers usually write more complex methods in Python than a control group, and they tend to use loop variables outside of a loop more often. Java programmers tend to redefine outer names more times than Python programmers, and both C++ and Java programmers write longer lines.
% Este paper do Horschig usou o GHTorrent. Será preferível mencionar isso, e meter o GHTorrent num parágrafo anterior?

Stack Overflow (SO) is an ever-present website in developers' lives, with many snippets available for solving both common and unique problems. In \cite{Yang_2017}, the presence of SO snippets in real projects, and what adaptations (if any) these snippets had is studied. They analyzed 909k non-fork Python projects, and found that the percentage of snippets found both in SO and GitHub (GH) is low - under 2\% of analyzed snippets, which results in just thousands of snippets. Nevertheless, there is some evidence of code flow from SO to GH.


% Acho que vale a pena remover este paper. Dá match de conceitos de job advertisements para o perfil de uma pessoa no GitHub mas não tem assim muito a ver com a história do repositório ou dos commits, é mais uma análise de língua natural feita nos READMEs de repos.
% Matching job advertisements' requirements with candidates' skill could make recruiters' jobs easier, as well as help developers find jobs more well suited to their strengths. An attempt to establish this relationship was developed in \cite{Hauff_2015}. The authors extracted concepts from job advertisements, as well as repositories (through the READMEs), and attempted to match developers to jobs based on their familiarity with the concepts;


% Nesta situações onde retiro texto de um paper, tenho que ter a citação logo a seguir? Ou percebe-se de onde vem?
Measuring developer contribution in an agile and distributed development context is not a trivial task. Since "an important portion of development time is spent on communication and manipulation of development support tools", a new model for contribution measurement was developed and explained in \cite{Gousios_2008}, which mixes repository data with traditional contribution metrics (lines of code) to get a more accurate contribution measure. The model is based on a function that applies weights to different actions on a repository. Committing translation files, including a bug report number on a commit message, or committing documentation files are examples of code-related actions. However, there are also non code-related actions, like creating or updating a new Wiki page, participating in IRC (keep in mind the paper was published in 2008), replying to a mailing list thread, or closing a bug. All of these are associated with positive weights, but there are some actions with negative weights - closing a bug that is then reopened, committing without messages, making large commits (with more than \textit{X} files), or making commits that generate bugs. To compute the weights, the authors first compute clusters of similar projects, since certain types of projects are expected to have more actions of certain types than others. Then, all of the considered events are counted across all projects of each cluster, and the weight $w_i$ for each action is "the percentage of contribution of each action category to the total number of actions". Manual weights are applied to the sum of all $w_i \times action_i$ for actions of a given type. These manual weights are chosen according to the needs of each project. This offers a contribution factor that is applied to developers and is summed to their total Lines of Code (LOC), resulting in a modern contribution metric.
% A explicação dos weights e agregações faz sentido?

% Posso ter a "cópia" das applications do paper, ou é preferivel ter as citações que eles também teem?
Code authorship attribution is an important research topic, with applications ranging from bug report assignments and software forensics to plagiarism detection\cite{Gong_2021}. In \cite{Gong_2021}, the revision histories and past contributions of developers are leveraged to try to find hidden code authors.



Finally, \cite{Gousios_2013} released the "GHTorrent Project", also available online \footnote{https://ghtorrent.org/}. Through a decentralized way, all data from GitHub events (like new commits, new authors, new issues - everything that may happen in a repository) is stored in a standardized form in a database. This way, researchers can scale their findings to many repositories, as well as combine data from different repositories more easily, as it's a matter of performing queries on a database rather than using an API. The paper also presents several research opportunities. % Vale a pena mencionar quais?
\cite{Seker_2020} investigated 172 studies that used this Database, and categorized them into several software engineering challenges. It also presented several pros and cons of GHTorrent, as well as challenges found using it.